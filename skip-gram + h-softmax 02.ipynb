{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from h_softmax import Tree\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus example: [['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']]\n",
      "vocab size: 8\n",
      "preprocessed: [[0, 1, 2, 3, 4, 5, 0, 6, 7]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"the quick brown fox jumps over the lazy dog\".split(' ')]\n",
    "print(f'corpus example: {corpus}')\n",
    "\n",
    "words = Counter()\n",
    "for doc in corpus:\n",
    "    for word in doc:\n",
    "        words[word] += 1\n",
    "\n",
    "vocab_size = len(words)\n",
    "print(f'vocab size: {vocab_size}')\n",
    "\n",
    "word_to_ix, ix_to_word = {}, {}\n",
    "for ix, (word, _) in enumerate(words.most_common()):\n",
    "    word_to_ix[word] = ix\n",
    "    ix_to_word[ix] = word\n",
    "\n",
    "corpus_preprocessed = list()\n",
    "for document in corpus:\n",
    "    corpus_preprocessed.append([word_to_ix[word] for word in document])\n",
    "print(f'preprocessed: {corpus_preprocessed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(corpus, window_size=2):\n",
    "    for document in corpus:\n",
    "        doc_len = len(document)\n",
    "        for ix in range(doc_len):\n",
    "            floor = max(0, ix-window_size)\n",
    "            ceil = min(doc_len, ix+window_size+1)\n",
    "            \n",
    "            X = document[ix]\n",
    "            \n",
    "            y = list()\n",
    "            for word in document[floor:ix]:\n",
    "                y.append(word)\n",
    "            for word in document[ix+1:ceil]:\n",
    "                y.append(word)\n",
    "            \n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModel(object):\n",
    "    \n",
    "    def __init__(self, vocab_size, h_size, learning_rate, seed=None):\n",
    "        \"\"\"\n",
    "        parameters\n",
    "        ----------\n",
    "        \n",
    "        vocabulary: list of unique words\n",
    "        h_size    : size of the hidden units\n",
    "        \"\"\"\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.eta = learning_rate\n",
    "        \n",
    "        self.w1   = np.random.randn(vocab_size, h_size)\n",
    "        self.tree = Tree(range(vocab_size), h_size)\n",
    "        \n",
    "        self._dw2 = np.zeros_like(self.tree.weights)\n",
    "    \n",
    "    def feed_forward(self, X, labels):\n",
    "        h = self.w1[None, X].T\n",
    "        \n",
    "        u_s = [np.dot(self.tree[label].T, h) for label in labels]\n",
    "        y = [self.sigmoid(u) for u in u_s]\n",
    "\n",
    "        return h, y\n",
    "    \n",
    "    def back_propagation(self, X, labels, y_preds, h):\n",
    "        dw1 = np.zeros((1, self.w1.shape[1]))\n",
    "        self._dw2 *= 0\n",
    "\n",
    "        for label, y_pred in zip(labels, y_preds):\n",
    "            error = [y-sign if sign == 1 else y for y, sign in zip(y_pred, self.tree.get_path(label))]\n",
    "            error = np.array(error).T\n",
    "\n",
    "            # error   -> 3x1\n",
    "            # weights -> 5x3\n",
    "            dw1 += np.dot(error, self.tree[label].T)\n",
    "            \n",
    "            dw2 = h * error\n",
    "            dw2 = dw2.T\n",
    "\n",
    "            for ix, w2_ix in enumerate(self.tree.get_indexes(label)):\n",
    "                self._dw2[:,w2_ix] += dw2[ix]\n",
    "\n",
    "        self.w1[None, X] -= self.eta * dw1\n",
    "\n",
    "        self.tree.weights -= self.eta * self._dw2\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1./(1.+np.exp(-x))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        h = self.w1[None, X].T\n",
    "        \n",
    "        self\n",
    "# model = EmbeddingModel(vocab_size, 5, 1e-3, 42)\n",
    "\n",
    "epochs = 150000\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for X, labels in get_data(corpus_preprocessed):\n",
    "        h, y_preds = model.feed_forward(X, labels)\n",
    "\n",
    "        for ix, label in enumerate(labels):\n",
    "            for sign, y_pred in zip(model.tree.get_path(label),  y_preds[ix]):\n",
    "                if sign == 1:\n",
    "                    loss += -np.sum(np.log(y_pred))\n",
    "                else:\n",
    "                    loss += -np.sum(np.log(1-y_pred))\n",
    "        \n",
    "        model.back_propagation(X, labels, y_preds, h)\n",
    "        \n",
    "    if epoch % 1500 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'lazy', 'dog']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.33210946e-01, 1.73457018e-05, 3.33243523e-01, 3.33270506e-01,\n",
       "       1.35890963e-10, 6.22835252e-09, 7.50563885e-05, 1.82615977e-04])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.zeros(8)\n",
    "\n",
    "for i in range(8):\n",
    "    path = model.tree.get_path(i)\n",
    "    \n",
    "    result[i] = np.prod(sigmoid(model.w1[1] @ (model.tree[i]*path)))\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>quick</th>\n",
       "      <th>brown</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>over</th>\n",
       "      <th>lazy</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.09898</td>\n",
       "      <td>-10.962166</td>\n",
       "      <td>-1.098882</td>\n",
       "      <td>-1.098801</td>\n",
       "      <td>-22.719168</td>\n",
       "      <td>-18.894154</td>\n",
       "      <td>-9.497271</td>\n",
       "      <td>-8.608125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       the      quick     brown       fox      jumps       over      lazy  \\\n",
       "0 -1.09898 -10.962166 -1.098882 -1.098801 -22.719168 -18.894154 -9.497271   \n",
       "\n",
       "        dog  \n",
       "0 -8.608125  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.log(result)[None], columns=list(word_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216.72592163085938"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 4 * 189378 * 300\n",
    "b / 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497.8179931640625"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 4 * 435000 * 300\n",
    "b / 2**20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
